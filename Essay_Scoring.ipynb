{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Automatic Essay Scoring Model"
      ],
      "metadata": {
        "id": "5iTvN5qbENLd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading necessary libraries"
      ],
      "metadata": {
        "id": "7bOVxWRtEQP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "# from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n"
      ],
      "metadata": {
        "id": "hehR9FgaCk7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading Data"
      ],
      "metadata": {
        "id": "dfbzSwJ6EWE4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/training_set_rel3.xls\"\n",
        "data = pd.read_excel(file_path)"
      ],
      "metadata": {
        "id": "XUttcssBCmX5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Pre-Processing"
      ],
      "metadata": {
        "id": "xkR8qjhREalH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = ['essay_id', 'essay_set', 'essay', 'domain1_score']\n",
        "data = data[columns_to_keep]\n",
        "\n",
        "data = data.dropna(subset=['essay', 'domain1_score'])"
      ],
      "metadata": {
        "id": "rZ-ku1waCtO5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'\\W', ' ', text)\n",
        "    tokens = word_tokenize(text)\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens if word not in stop_words]\n",
        "    return ' '.join(tokens)\n",
        "\n",
        "data['processed_essay'] = data['essay'].apply(preprocess_text)\n",
        "\n",
        "data['essay_length'] = data['essay'].apply(lambda x: len(x.split()))"
      ],
      "metadata": {
        "id": "ieZNJa6lCvqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Feature Extraction Using TF-IDF"
      ],
      "metadata": {
        "id": "lHgAed3OEtGc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature extraction using TF-IDF\n",
        "vectorizer = TfidfVectorizer(ngram_range=(1, 2), max_features=5000)\n",
        "X = vectorizer.fit_transform(data['processed_essay'])"
      ],
      "metadata": {
        "id": "_TRgxVJLCyyB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Preparing the Target Variable"
      ],
      "metadata": {
        "id": "pQiZ9lZGE1Hp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Target variable\n",
        "scaler = MinMaxScaler()\n",
        "y = scaler.fit_transform(data[['domain1_score']])"
      ],
      "metadata": {
        "id": "A4fBalFRC2Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Train-Test Split"
      ],
      "metadata": {
        "id": "FKGsaA1eE3dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test, train_indices, test_indices = train_test_split(X, y, range(len(data)), test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "LfGwKBq2C7Kf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Training with Random Forest"
      ],
      "metadata": {
        "id": "08pzUn97E56J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model training\n",
        "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "CR2g-oE1C9qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predictions and Evaluation"
      ],
      "metadata": {
        "id": "hITpypE1E-lX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "a37j6HcaC_52"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inverse scaling to get actual scores"
      ],
      "metadata": {
        "id": "9pBUI-GOFBdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_inverse = scaler.inverse_transform(y_pred.reshape(-1, 1))"
      ],
      "metadata": {
        "id": "C-mtcWr0DCOB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model Evaluation"
      ],
      "metadata": {
        "id": "jQnx_0t9FGYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(f'MSE: {mse}, MAE: {mae}, R^2 Score: {r2}')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9J7LY3ZsS9r",
        "outputId": "eb8bb4b2-6f8d-429f-f05d-1327bc8e6c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.0020016455070241018, MAE: 0.0210752482451635, R^2 Score: 0.9134204638753711\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Displaying the Results"
      ],
      "metadata": {
        "id": "P_OonyGGFJFQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_df = pd.DataFrame({\n",
        "    'essay_id': data.iloc[test_indices]['essay_id'].values,\n",
        "    'predicted_score': y_pred_inverse.flatten()\n",
        "})\n",
        "\n",
        "print(predictions_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4uDAfL-v9C70",
        "outputId": "649ffd93-941e-44ab-f117-c0cd8148148e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      essay_id  predicted_score\n",
            "0         7398             1.56\n",
            "1        13472             2.69\n",
            "2         7004             1.85\n",
            "3         6790             1.94\n",
            "4         4599             3.12\n",
            "...        ...              ...\n",
            "2591      9600             2.36\n",
            "2592     15200             3.07\n",
            "2593      6256             1.11\n",
            "2594      4509             2.79\n",
            "2595        80             9.79\n",
            "\n",
            "[2596 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Interpret the accuracy\n",
        "if r2 < 0:\n",
        "    print(\"The model does not explain any of the variability in the target variable.\")\n",
        "elif r2 < 0.5:\n",
        "    print(\"The model has a weak fit.\")\n",
        "elif r2 < 0.75:\n",
        "    print(\"The model has a moderate fit.\")\n",
        "else:\n",
        "    print(\"The model has a strong fit.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c19SqCc1Gd17",
        "outputId": "c4a2e26c-c606-4882-d05e-557b76ed0dbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has a strong fit.\n"
          ]
        }
      ]
    }
  ]
}